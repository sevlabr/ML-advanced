The task was to create Seq2Seq NMT system for RU-EN language pair using at least 3 different approaches.
[Baseline solution](https://github.com/girafe-ai/ml-mipt/blob/21f_advanced/homeworks_advanced/lab01_nlp/lab1_02_nlp_part2_nmt.ipynb)
was provided.

Solutions presented are inspired by baseline solution, great [series](https://github.com/bentrevett/pytorch-seq2seq) of Seq2Seq tutorials by
[bentrevett](https://github.com/bentrevett) and partially inspired by gorgeous [tutotials](https://github.com/bentrevett/pytorch-image-classification)
dedicated to image classification by the same author.

The solution consists of 4 main parts. Ones denoted by numbers are NMT models based on different architectures and using various learning techniques.
The last part are [results](https://github.com/sevlabr/ML-MIPT-advanced/blob/main/NLP%20Lab/Part%202/Results.ipynb) where summary of all experiments is provided.

Colab versions:
1. [DistilBERT Encoder](https://colab.research.google.com/drive/1sT5tPaRasXq2M55whxb1hPnz-adBan6e?usp=sharing)
2. [Base LSTM with few additional features](https://colab.research.google.com/drive/1ZI7N4Tm2UIR1-oqTI3OR5xV53vTS3D8B?usp=sharing)
3. [CNN-Transformer and enhanced learning techniques](https://colab.research.google.com/drive/1FSQUn3Iy10Ft05WUSxdPV6rAJ7odTbCe?usp=sharing)

[Results](https://colab.research.google.com/drive/1X5zhnn7LnjKgZpB2IuRJzd940vCAXRn8?usp=sharing)
